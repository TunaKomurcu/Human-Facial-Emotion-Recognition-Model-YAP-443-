{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75835c0-355b-4d66-a899-36ee14d52ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Gerekli Kütüphaneler ve Ayarlar\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Cihaz ayarı (GPU varsa GPU, yoksa CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64bfde-f2b2-4c3c-904a-17a8f101998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = self.sigmoid(avg_out + max_out)\n",
    "        return x * out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d632b-bb67-4640-971c-559a4f0ca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return F.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee2dab-ccbd-4fcd-aa7c-bfcd0dd27a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HybridEmotionCNN, self).__init__()\n",
    "        \n",
    "        # --- Convolution + BatchNorm + CBAM ---\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)  # **Tek kanal giriş**\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.cbam1 = CBAMBlock(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.cbam2 = CBAMBlock(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.cbam3 = CBAMBlock(256)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.cbam4 = CBAMBlock(512)\n",
    "\n",
    "        # --- Residual Blocks ---\n",
    "        self.residual1 = ResidualBlock(512)\n",
    "        self.residual2 = ResidualBlock(512)\n",
    "        self.residual3 = ResidualBlock(512)\n",
    "\n",
    "        # --- Fully Connected Katmanlar ---\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 2048)  # **Düzleştirme işlemi için uygun boyut**\n",
    "        self.bn6 = nn.LayerNorm(2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, num_classes)  # 6 sınıf çıktısı\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- Convolutional Bloklar ---\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.cbam1(x)\n",
    "\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.cbam2(x)\n",
    "\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.cbam3(x)\n",
    "\n",
    "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.cbam4(x)\n",
    "\n",
    "        # --- Residual Bloklar ---\n",
    "        x = self.residual1(x)\n",
    "        x = self.residual2(x)\n",
    "        x = self.residual3(x)\n",
    "\n",
    "        # **HATA DÜZELTİLDİ: Flatten işlemi eksikti**\n",
    "        x = torch.flatten(x, 1)  # Fully Connected katmanlar için düzleştirme\n",
    "\n",
    "        # --- Fully Connected Katmanlar ---\n",
    "        x = F.relu(self.bn6(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)  # Sonuç: 6 sınıfın olasılıkları\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a3fe8-1d90-4aa8-b7ff-27632804491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aynı model yapısını oluşturun ve cihazı ayarlayın\n",
    "model = HybridEmotionCNN(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321f524-7b87-412f-9186-3dbce4d0064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer ve Loss fonksiyonu tanımlanması\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a4cc0-bf5a-4222-b6da-62715bb790e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Kök klasör\n",
    "base_dir = \"C:/Users/Tuna/Downloads/images\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"validation\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Sınıflar (örneğin: happy, sad, etc.)\n",
    "classes = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
    "\n",
    "# Test klasörünü oluştur\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
    "\n",
    "for cls in classes:\n",
    "    print(f\"\\n▶️ {cls} sınıfı için örnekler hazırlanıyor...\")\n",
    "\n",
    "    # Tüm resimleri topla\n",
    "    train_cls_path = os.path.join(train_dir, cls)\n",
    "    val_cls_path = os.path.join(val_dir, cls)\n",
    "\n",
    "    all_images = []\n",
    "\n",
    "    for folder in [train_cls_path, val_cls_path]:\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        all_images += [(os.path.join(folder, f), f) for f in files]\n",
    "\n",
    "    # Karıştır\n",
    "    random.shuffle(all_images)\n",
    "\n",
    "    total_count = len(all_images)\n",
    "    test_count = int(0.2 * total_count)\n",
    "\n",
    "    print(f\"Toplam: {total_count} -> Test'e ayrılacak: {test_count} görsel\")\n",
    "\n",
    "    # Test için seçilen görselleri yeni klasöre kopyala\n",
    "    selected_test_images = all_images[:test_count]\n",
    "    for src_path, filename in selected_test_images:\n",
    "        dst_path = os.path.join(test_dir, cls, filename)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "    print(f\"✅ {cls}: Test seti tamamlandı. ({len(selected_test_images)} resim)\")\n",
    "\n",
    "print(\"\\n🎉 Tüm sınıflar için test seti başarıyla oluşturuldu!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31214f-261f-4a1a-ae5a-dd0bdeb46d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: CNN Modeli Tanımlaması (DeepCNNFeatureExtractor)\n",
    "# Bu model, 1 kanallı (grayscale) 64x64 görüntüler için sıfırdan eğitilecek şekilde tasarlanmıştır.\n",
    "class DeepCNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNNFeatureExtractor, self).__init__()\n",
    "        # Blok 1: 1 -> 32 kanal\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 64x64 -> 32x32\n",
    "\n",
    "        # Blok 2: 32 -> 64 kanal\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4   = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
    "\n",
    "        # Blok 3: 64 -> 128 kanal\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5   = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6   = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
    "\n",
    "        # Tam bağlantılı katman: Özellik vektörü boyutu 128*8*8 = 8192'den 256'ya indirme\n",
    "        self.fc = nn.Linear(128 * 8 * 8, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        features = self.fc(x)  # 256 boyutlu özellik vektörü\n",
    "        return features\n",
    "\n",
    "# Örnek test (isteğe bağlı)\n",
    "if __name__ == '__main__':\n",
    "    dummy = torch.randn(1, 1, 64, 64).to(device)\n",
    "    feat = DeepCNNFeatureExtractor().to(device)(dummy)\n",
    "    print(\"CNN özellik vektörü boyutu:\", feat.shape)  # Beklenen: [1, 256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c5718-b101-4533-b69f-414583aa82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: HOG Özellik Çıkarım Fonksiyonu\n",
    "def extract_hog_features(image, pixels_per_cell=(8,8), cells_per_block=(2,2), orientations=9):\n",
    "    \"\"\"\n",
    "    image: Giriş görüntüsü (grayscale, numpy array, boyut: 64x64)\n",
    "    HOG özellikleri çıkarılır.\n",
    "    \"\"\"\n",
    "    # image'ı float formatına çeviriyoruz\n",
    "    image = np.float32(image) / 255.0\n",
    "    features = hog(image, orientations=orientations, pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block, block_norm='L2-Hys', feature_vector=True)\n",
    "    return features\n",
    "\n",
    "# Örnek test\n",
    "test_image = np.random.randint(0, 256, (64, 64), dtype=np.uint8)\n",
    "hog_feat = extract_hog_features(test_image)\n",
    "print(\"HOG özelliği boyutu:\", hog_feat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524764f-db33-4014-9e11-ce3773211652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: LPG Özellik Çıkarım Fonksiyonu (Sobel Gradyanları ile)\n",
    "def extract_lpg_features(image):\n",
    "    \"\"\"\n",
    "    image: Giriş görüntüsü (grayscale, numpy array, boyut: 64x64)\n",
    "    Sobel gradyanları kullanılarak yön histogramı hesaplanır.\n",
    "    \"\"\"\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    angle = cv2.phase(grad_x, grad_y, angleInDegrees=True)\n",
    "    hist = cv2.calcHist([np.uint8(angle)], [0], None, [36], [0, 360])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "# Örnek test\n",
    "lpg_feat = extract_lpg_features(test_image)\n",
    "print(\"LPG özelliği boyutu:\", lpg_feat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a716b5-5f8f-4a76-b8c6-760a827cbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Hibrit Özellik Çıkarım Fonksiyonu (CNN, HOG, LPG)\n",
    "def extract_hybrid_features(image_tensor, cnn_model, original_image):\n",
    "    \"\"\"\n",
    "    image_tensor: CNN için ön işlenmiş tensör (1x64x64)\n",
    "    original_image: Orijinal veya yeniden boyutlandırılmış grayscale görüntü (64x64 numpy array)\n",
    "    \"\"\"\n",
    "    # CNN özellikleri\n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        feat = cnn_model(image_tensor.unsqueeze(0).to(device))\n",
    "        cnn_feat = feat.squeeze(0).cpu().numpy()  # Boyut: [256]\n",
    "\n",
    "    hog_feat = extract_hog_features(original_image)  # Boyut: örneğin ~1764\n",
    "    lpg_feat = extract_lpg_features(original_image)  # Boyut: [36]\n",
    "\n",
    "    # Hibrit özellik vektörü: CNN + HOG + LPG\n",
    "    hybrid_feat = np.concatenate([cnn_feat, hog_feat, lpg_feat])\n",
    "    return hybrid_feat\n",
    "\n",
    "# Örnek test\n",
    "dummy_tensor = torch.randn(1, 64, 64)  # rastgele örnek (1x64x64)\n",
    "hybrid_test = extract_hybrid_features(dummy_tensor, DeepCNNFeatureExtractor().to(device), test_image)\n",
    "print(\"Hibrit özellik vektörü boyutu:\", hybrid_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fca54d-e4b2-4834-b9c5-7f78369c11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Dataset Sınıfı ve Transform Ayarları\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class EmotionDatasetFromSamples(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        \"\"\"\n",
    "        samples: [(img_path, label)] formatında örneklerin listesi\n",
    "        transform: Resim için uygulanacak dönüşümler\n",
    "        \"\"\"\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        # Orijinal görüntüyü cv2 ile oku ve yeniden boyutlandır\n",
    "        original_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if original_image is None:\n",
    "            raise ValueError(f\"Resim okunamadı: {img_path}\")\n",
    "        original_image = cv2.resize(original_image, (64, 64))\n",
    "        # PIL ile açıp grayscale'e çevir\n",
    "        image_pil = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image_pil)\n",
    "        else:\n",
    "            from torchvision.transforms import ToTensor\n",
    "            image_tensor = ToTensor()(image_pil)\n",
    "        return image_tensor, original_image, label\n",
    "        \n",
    "# Transform: Grayscale, Resize (64x64), ToTensor, Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41330e25-6411-4567-b6af-dbc10b1263bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: Hibrit Özellik Çıkarım Fonksiyonu ve Veri Yollarının Ayarlanması\n",
    "def extract_hybrid_features_from_dataset(dataset, cnn_model):\n",
    "    features_list, labels_list = [], []\n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (img_tensor, original_image, label) in enumerate(dataset):\n",
    "            feat = extract_hybrid_features(img_tensor, cnn_model, original_image)\n",
    "            features_list.append(feat)\n",
    "            labels_list.append(label)\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"{idx} örnek işlendi...\")\n",
    "    return np.array(features_list), np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998eac02-0f23-4b0d-8d54-172cbfca4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Mevcut klasörler\n",
    "base_dir = \"C:/Users/Tuna/Downloads/images\"\n",
    "existing_splits = [\"train\", \"validation\", \"test\"]\n",
    "temp_pool_dir = \"C:/Users/Tuna/Downloads/images_all_temp\"  # geçici havuz\n",
    "\n",
    "# Geçici havuz klasörünü oluştur\n",
    "os.makedirs(temp_pool_dir, exist_ok=True)\n",
    "\n",
    "# Tüm verileri geçici havuza kopyala (var olan klasör yapısı korunmadan)\n",
    "for split in existing_splits:\n",
    "    split_dir = os.path.join(base_dir, split)\n",
    "    classes = [d for d in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, d))]\n",
    "    for cls in classes:\n",
    "        class_path = os.path.join(split_dir, cls)\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        # Geçici havuzda her sınıf için klasör oluştur\n",
    "        temp_class_dir = os.path.join(temp_pool_dir, cls)\n",
    "        os.makedirs(temp_class_dir, exist_ok=True)\n",
    "        for img in images:\n",
    "            src = os.path.join(class_path, img)\n",
    "            dst = os.path.join(temp_class_dir, img)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"Tüm veriler geçici havuza kopyalandı:\", temp_pool_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cde917-c507-491d-b9bc-d087b1f33444",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"C:\\\\Users\\\\Tuna\\\\Downloads\\\\images_all_temp\"  \n",
    "all_samples = []\n",
    "\n",
    "classes = sorted(os.listdir(train_folder))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classes = sorted(os.listdir(train_folder))\n",
    "\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(train_folder, class_name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        if os.path.exists(img_path):\n",
    "            all_samples.append((img_path, label))\n",
    "        else:\n",
    "            print(\"Eksik dosya:\", img_path)\n",
    "            \n",
    "# Eğitim ve test verilerini ayır (60% eğitim, 40% test)\n",
    "train_samples, test_samples = train_test_split(\n",
    "    all_samples, test_size=0.4, stratify=[label for _, label in all_samples], random_state=42\n",
    ")\n",
    "\n",
    "# Doğrulama ve test verilerini ayır (20% + 20%)\n",
    "val_samples, test_samples = train_test_split(\n",
    "    test_samples, test_size=0.5, stratify=[label for _, label in test_samples], random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Yeni datasetleri oluştur\n",
    "train_dataset = EmotionDatasetFromSamples(train_samples, transform=transform)\n",
    "val_dataset = EmotionDatasetFromSamples(val_samples, transform=transform)\n",
    "test_dataset = EmotionDatasetFromSamples(test_samples, transform=transform)\n",
    "\n",
    "\n",
    "# Dataloaders oluştur\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(\"Sınıflar:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba9cd5-f14e-4625-a6e3-ef4050292c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik Çıkarımı\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Parametre aralığını daraltılmış ve n_iter belirlenmiş parametre dağılımı\n",
    "param_distributions = {\n",
    "    'C': [0.1, 1],\n",
    "    'gamma': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# SVM için temel fonksiyon\n",
    "def base_svm(**kwargs):\n",
    "    kwargs.setdefault('class_weight', 'balanced')\n",
    "    return SVC(kernel=\"rbf\", **kwargs)\n",
    "\n",
    "# Hibrit özellik çıkarımı\n",
    "print(\"Hibrit öznitelikler çıkarılıyor (CNN + HOG + LPG)...\")\n",
    "\n",
    "# Burada, tüm verinin yeniden bölünmüş datasetlerini (train, validation, test) kullanıyoruz.\n",
    "# Bu datasetlerin, tüm veriyi bir havuzda toplayıp 60/20/20 oranında böldüğünüz bölümde oluşturduğunuzu varsayıyoruz.\n",
    "X_train, y_train = extract_hybrid_features_from_dataset(train_dataset, DeepCNNFeatureExtractor().to(device))\n",
    "X_val, y_val     = extract_hybrid_features_from_dataset(val_dataset, DeepCNNFeatureExtractor().to(device))\n",
    "X_test, y_test   = extract_hybrid_features_from_dataset(test_dataset, DeepCNNFeatureExtractor().to(device))\n",
    "\n",
    "print(\"Öznitelik çıkarımı tamamlandı.\")\n",
    "print(\"Train veri boyutu: \", X_train.shape)\n",
    "print(\"Validation veri boyutu: \", X_val.shape)\n",
    "print(\"Test veri boyutu: \", X_test.shape)\n",
    "\n",
    "# PCA ile boyut indirgeme: Örneğin, orijinal özellik boyutunu 500'e indiriyoruz\n",
    "pca = PCA(n_components=500, random_state=42)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_val_reduced   = pca.transform(X_val)\n",
    "X_test_reduced  = pca.transform(X_test)\n",
    "\n",
    "print(\"PCA sonrası boyutlar:\")\n",
    "print(\"Train: \", X_train_reduced.shape)\n",
    "print(\"Validation: \", X_val_reduced.shape)\n",
    "print(\"Test: \", X_test_reduced.shape)\n",
    "\n",
    "# PCA nesnesini kaydedelim\n",
    "joblib.dump(pca, \"pca_transformer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e07865-973f-4ede-96ce-7e0d04cf1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint kontrolü ve yüklemesi\n",
    "checkpoint_path = \"checkpoint.pth\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    if \"epoch\" in checkpoint:\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "        print(f\"✅ Eğitime {start_epoch}. epoch'tan devam ediliyor.\", flush=True)\n",
    "    else:\n",
    "        print(\"⚠️ Checkpoint dosyasında 'epoch' bilgisi bulunamadı! Eğitim 0'dan başlatılıyor.\", flush=True)\n",
    "        start_epoch = 0\n",
    "else:\n",
    "    print(\"⚠️ Checkpoint bulunamadı! Eğitim 0'dan başlatılıyor.\", flush=True)\n",
    "    start_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2935d5-0bed-4633-8658-00ad1e394fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"cnn_model_weights.pth\", map_location=device, weights_only=True)\n",
    "print(checkpoint.keys())  # Checkpoint içindeki tüm anahtarları yazdır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fc23b-b487-40d2-9880-e4de593a335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Alternatif checkpoint kontrolü (weights dosyası)\n",
    "checkpoint_weights_path = \"cnn_model_weights.pth\"\n",
    "if os.path.exists(checkpoint_weights_path):\n",
    "    checkpoint = torch.load(checkpoint_weights_path, map_location=device)\n",
    "    print(\"Checkpoint anahtarları:\", checkpoint.keys(), flush=True)\n",
    "    if \"epoch\" in checkpoint:\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\"✅ Eğitime {start_epoch}. epoch'tan devam ediliyor.\", flush=True)\n",
    "    else:\n",
    "        print(\"⚠️ Checkpoint dosyasında 'epoch' bilgisi bulunamadı! Eğitim 0'dan başlatılıyor.\", flush=True)\n",
    "        start_epoch = 0\n",
    "else:\n",
    "    print(\"⚠️ Alternatif checkpoint bulunamadı! Eğitim 0'dan başlatılıyor.\", flush=True)\n",
    "    start_epoch = 0\n",
    "\n",
    "epochs = 10  # Kaç epoch devam edeceğini belirle\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # tqdm ile batch ilerlemesini gösteriyoruz\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100)\n",
    "    for images, _, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Ortalama Loss: {avg_loss:.4f}\", flush=True)\n",
    "\n",
    "    # Her epoch sonunda ağırlıkları ve eğitimin ilerleme durumunu kaydet\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict()\n",
    "    }, \"checkpoint2.pth\")\n",
    "\n",
    "print(\"✅ Eğitim tamamlandı ve model kaydedildi!\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb497c-b03c-49a5-b9e6-bbcdf62409a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ağırlıklarını .pkl uzantılı dosyaya kaydet\n",
    "with open(\"cnn_model_weights.pkl\", \"wb\") as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "\n",
    "print(\"✅ Model ağırlıkları cnn_model_weights.pkl dosyasına kaydedildi!\", flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
